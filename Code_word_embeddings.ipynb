{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasmine-houri/Word_embeddings/blob/main/Code_word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7SN5USFEIIK3"
      },
      "source": [
        "<h1><center><strong><font color=\"navy\">Introduction to gender bias detection using word embeddings</font></strong></center></h1>\n",
        "\n",
        "\n",
        "<center>\n",
        "Yasmine Houri  \n",
        "\n",
        "École nationale de la statistique et de l'administration économique, France"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6mJg1g3apaz"
      },
      "source": [
        "This is an introduction to word embeddings, as preliminary work for my PhD proposal on the following subject:  \n",
        "\n",
        "**Gendered representations of power in France: a digital analysis of traces of occupational stratification in online texts**. \n",
        "\n",
        "This research is supervied by **Jean-Philippe Cointet** (data scientist at médialab, Sciences Po, Paris, France), and **Achim Edelmann** (sociologist at médialab, Sciences Po, Paris, France).  \n",
        "Feel free to email me at yasmine.houri@ensae.fr if you have any questions.  \n",
        "\n",
        "This notebook is freely adapted from https://www.tensorflow.org/text/guide/word_embeddings and https://notebook.community/henchc/Rediscovering-Text-as-Data/11-Word-Embeddings/01-Word-Embeddings. All due credits belong to the authors of these two pages. I will be using data from: https://txtlab.org/2016/01/txtlab450-a-data-set-of-multilingual-novels-for-teaching-and-research/ ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conceptual introduction to basic word embeddings"
      ],
      "metadata": {
        "id": "MPz01Ie6HE8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Representing text as numbers\n",
        "\n",
        "Machine learning models take vectors (arrays of numbers) as input. When working with text, the first thing you must do is come up with a strategy to convert strings to numbers (or to \"vectorize\" the text) before feeding it to the model. In this section, you will look at three strategies for doing so.\n",
        "\n",
        "### One-hot encodings\n",
        "\n",
        "As a first idea, you might \"one-hot\" encode each word in your vocabulary. Consider the sentence \"The cat sat on the mat\". The vocabulary (or unique words) in this sentence is (cat, mat, on, sat, the). To represent each word, you will create a zero vector with length equal to the vocabulary, then place a one in the index that corresponds to the word. This approach is shown in the following diagram.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/text/blob/master/docs/guide/images/one-hot.png?raw=1\" alt=\"Diagram of one-hot encodings\" width=\"400\" />\n",
        "\n",
        "To create a vector that contains the encoding of the sentence, you could then concatenate the one-hot vectors for each word.\n",
        "\n",
        "Key point: This approach is inefficient. A one-hot encoded vector is sparse (meaning, most indices are zero). Imagine you have 10,000 words in the vocabulary. To one-hot encode each word, you would create a vector where 99.99% of the elements are zero.\n",
        "\n",
        "### Encode each word with a unique number\n",
        "\n",
        "A second approach you might try is to encode each word using a unique number. Continuing the example above, you could assign 1 to \"cat\", 2 to \"mat\", and so on. You could then encode the sentence \"The cat sat on the mat\" as a dense vector like [5, 1, 4, 3, 5, 2]. This approach is efficient. Instead of a sparse vector, you now have a dense one (where all elements are full).\n",
        "\n",
        "There are two downsides to this approach, however:\n",
        "\n",
        "* The integer-encoding is arbitrary (it does not capture any relationship between words).\n",
        "\n",
        "* An integer-encoding can be challenging for a model to interpret. A linear classifier, for example, learns a single weight for each feature. Because there is no relationship between the similarity of any two words and the similarity of their encodings, this feature-weight combination is not meaningful.\n",
        "\n",
        "### Word embeddings\n",
        "\n",
        "Word embeddings give us a way to use an efficient, dense representation in which similar words have a similar encoding. Importantly, you do not have to specify this encoding by hand. An embedding is a dense vector of floating point values (the length of the vector is a parameter you specify). Instead of specifying the values for the embedding manually, they are trainable parameters (weights learned by the model during training, in the same way a model learns weights for a dense layer). It is common to see word embeddings that are 8-dimensional (for small datasets), up to 1024-dimensions when working with large datasets. A higher dimensional embedding can capture fine-grained relationships between words, but takes more data to learn.\n",
        "\n",
        "<img src=\"https://github.com/tensorflow/text/blob/master/docs/guide/images/embedding2.png?raw=1\" alt=\"Diagram of an embedding\" width=\"400\"/>\n",
        "\n",
        "Above is a diagram for a word embedding. Each word is represented as a 4-dimensional vector of floating point values. Another way to think of an embedding is as \"lookup table\". After these weights have been learned, you can encode each word by looking up the dense vector it corresponds to in the table.\n",
        "\n",
        "However, one-hot encoding and dense encoding both fail to encode relationships between words. In this analysis, I will be using one of the most common and better performing methods of word embedding named Word2Vec (read Mikolov, Tomas, et al. \"Efficient estimation of word representations in vector space.\" (2013) for more information)."
      ],
      "metadata": {
        "id": "PPnHRGo1HJh-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Set up the work environment"
      ],
      "metadata": {
        "id": "zszLfPl0PxDZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZUQErGewZxE"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RutaI-Tpev3T"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "from datascience import *\n",
        "import numpy as np\n",
        "from scipy.spatial.distance import cosine\n",
        "import gensim\n",
        "import nltk\n",
        "from string import punctuation\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBFctV8-JZOc"
      },
      "source": [
        "### Load the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPO4_UmfF0KH"
      },
      "outputs": [],
      "source": [
        "url = \"https://raw.githubusercontent.com/yasmine-houri/Word_embeddings/main/\"\n",
        "\n",
        "metadata_tb = pd.read_csv(url+'Data/2_txtlab_Novel150.csv').drop('Unnamed: 0', axis=1)\n",
        "\n",
        "fiction_path = url+'Data/'\n",
        "\n",
        "novel_list = []\n",
        "\n",
        "import requests\n",
        "# Iterate through filenames in metadata table\n",
        "for filename in metadata_tb['filename']:\n",
        "    \n",
        "    # Read in novel text as single string, make lowercase\n",
        "    url = fiction_path + filename\n",
        "    novel = requests.get(url)\n",
        "    novel.encoding = 'utf-8-sig'\n",
        "    \n",
        "    # Add novel text as single string to master list\n",
        "    novel_list.append(novel.text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGicgV5qT0wh"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MlsXzo-ZlfK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10c1f9f5-52e3-4fc6-e29b-f8716e1aa887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "def fast_tokenize(text):\n",
        "    \n",
        "    # Iterate through text removing punctuation characters\n",
        "    no_punct = \"\".join([char for char in text if char not in punctuation])\n",
        "    \n",
        "    # Split text over whitespace into list of words\n",
        "    tokens = no_punct.split()\n",
        "    \n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# randomlist = []\n",
        "# for i in range(0,50):\n",
        "#   n = random.randint(0,len(novel_list)-1)\n",
        "#   randomlist.append(n)\n",
        "# randomlist= tuple(randomlist)\n",
        "\n",
        "# short_list = [novel_list[i] for i in randomlist]  "
      ],
      "metadata": {
        "id": "SnY02uDQKG5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [sentence for novel in novel_list for sentence in sent_tokenize(novel)]"
      ],
      "metadata": {
        "id": "msU98LOjCEz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence = [fast_tokenize(sentence.lower()) for sentence in sentences]"
      ],
      "metadata": {
        "id": "F6ZbaPogCRGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence = [sentence for sentence in words_by_sentence if sentence != []]"
      ],
      "metadata": {
        "id": "EM7c3bFPCRj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Detection of gender bias in the entire period"
      ],
      "metadata": {
        "id": "BslfeQNMFsTO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjLNgKO7W2fe"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec is the most prominent word embedding algorithm. Word embedding generally attempts to identify semantic relationships between words by observing them in context.\n",
        "\n",
        "Imagine that each word in a novel has its meaning determined by the ones that surround it in a limited window. For example, in Moby Dick's first sentence, “me” is paired on either side by “Call” and “Ishmael.” After observing the windows around every word in the novel (or many novels), the computer will notice a pattern in which “me” falls between similar pairs of words to “her,” “him,” or “them.” Of course, the computer had gone through a similar process over the words “Call” and “Ishmael,” for which “me” is reciprocally part of their contexts. This chaining of signifiers to one another mirrors some of humanists' most sophisticated interpretative frameworks of language.\n",
        "\n",
        "The two main flavors of Word2Vec are CBOW (Continuous Bag of Words) and Skip-Gram, which can be distinguished partly by their input and output during training. Skip-Gram takes a word of interest as its input (e.g. \"me\") and tries to learn how to predict its context words (\"Call\",\"Ishmael\"). CBOW does the opposite, taking the context words (\"Call\",\"Ishmael\") as a single input and tries to predict the word of interest (\"me\").\n",
        "\n",
        "In general, CBOW is is faster and does well with frequent words, while Skip-Gram potentially represents rare words better."
      ],
      "metadata": {
        "id": "kax6tdmymWxK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word2Vec Features  \n",
        "\n",
        "* `size`: Number of dimensions for word embedding model\n",
        "* `window`: Number of context words to observe in each direction\n",
        "* `min_count`: Minimum frequency for words included in model\n",
        "* `sg` (Skip-Gram): '0' indicates CBOW model; '1' indicates Skip-Gram\n",
        "* `alpha`: Learning rate (initial); prevents model from over-correcting, enables finer tuning\n",
        "* `iterations`: Number of passes through dataset\n",
        "* `batch_words`: Number of words to sample from data during each pass  \n",
        "\n",
        "Note: cell below uses default value for each argument"
      ],
      "metadata": {
        "id": "5fJ6xJiimbrE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W4Hg3IHFt4Px"
      },
      "outputs": [],
      "source": [
        "model = gensim.models.Word2Vec(words_by_sentence, size=100, window=5, \\\n",
        "                               min_count=5, sg=0, alpha=0.025, iter=15, batch_words=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KCoA6qwqP836"
      },
      "source": [
        "## Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Diplomate (homme/femme): \", model.similarity('homme','diplomate')/model.similarity('femme','diplomate'))\n",
        "print(\"Cadre (homme/femme): \", model.similarity('homme','cadre')/model.similarity('femme','cadre'))\n",
        "print(\"Artiste (homme/femme): \", model.similarity('homme','artiste')/model.similarity('femme','artiste'))\n",
        "print(\"Officier (homme/femme): \", model.similarity('homme','officier')/model.similarity('femme','officier'))\n",
        "print(\"Cuisinier (homme/femme): \", model.similarity('homme','cuisinier')/model.similarity('femme','cuisinière'))\n",
        "print(\"Servant (homme/femme): \", model.similarity('homme','servant')/model.similarity('femme','servante'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXa0nrhrRCtD",
        "outputId": "3540f223-1fa0-4826-e7d0-0ca18eb6dd02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Diplomate (homme/femme):  3.39055\n",
            "Cadre (homme/femme):  -1.27337\n",
            "Artiste (homme/femme):  2.01439\n",
            "Officier (homme/femme):  3.80869\n",
            "Cuisinier (homme/femme):  0.583223\n",
            "Servant (homme/femme):  -0.107831\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualisations"
      ],
      "metadata": {
        "id": "UukGcBVARGRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar(positive='homme')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvYgStNoTeaR",
        "outputId": "4edb7280-dba9-49ec-c3f4-618986a87550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('garçon', 0.7630212306976318),\n",
              " ('ouvrier', 0.7295625805854797),\n",
              " ('abbé', 0.698989987373352),\n",
              " ('officier', 0.6971719264984131),\n",
              " ('animal', 0.6933426260948181),\n",
              " ('gentilhomme', 0.6898995041847229),\n",
              " ('intrigant', 0.68001389503479),\n",
              " ('enfant', 0.6695951223373413),\n",
              " ('alsacien', 0.6691569089889526),\n",
              " ('écrivain', 0.6669896245002747)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('femme')"
      ],
      "metadata": {
        "id": "RYWAZgqeL77u",
        "outputId": "3b65ac57-d02c-4dae-bc6c-10f7343ba2cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('fille', 0.9250227212905884),\n",
              " ('demoiselle', 0.8070782423019409),\n",
              " ('maîtresse', 0.776763379573822),\n",
              " ('comédienne', 0.7609223127365112),\n",
              " ('mère', 0.7494492530822754),\n",
              " ('rivale', 0.7487567067146301),\n",
              " ('cousine', 0.748172402381897),\n",
              " ('actrice', 0.7472723722457886),\n",
              " ('paysanne', 0.7403960824012756),\n",
              " ('soeur', 0.7387897372245789)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.most_similar('femme')"
      ],
      "metadata": {
        "id": "JxK7EwVvTcco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "her_tokens = [token for token,weight in model.most_similar(['femme','homme'], topn=30)]\n",
        "vectors = [model[word] for word in her_tokens]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1bXcX4_SpVr",
        "outputId": "9b803faf-4a06-4812-db8b-223f9b68e1d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import pairwise\n",
        "dist_matrix = pairwise.pairwise_distances(vectors, metric='cosine')\n",
        "from sklearn.manifold import MDS\n",
        "mds = MDS(n_components = 2, dissimilarity='precomputed')\n",
        "embeddings = mds.fit_transform(dist_matrix)"
      ],
      "metadata": {
        "id": "aSYtfx76S4ir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "_, ax = plt.subplots(figsize=(8,8))\n",
        "ax.scatter(embeddings[:,0], embeddings[:,1], alpha=0)\n",
        "for i in range(len(vectors)):\n",
        "    ax.annotate(her_tokens[i], ((embeddings[i,0], embeddings[i,1])))\n",
        "# plt.plot([-0.4, 0.6], [-0.4, 0.25], 'k-')"
      ],
      "metadata": {
        "id": "DH9hgYf3S8oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center> Detection of gender bias evolution over time"
      ],
      "metadata": {
        "id": "15padntVFdJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data into time sections"
      ],
      "metadata": {
        "id": "J3P8thP9GBn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata_tb_17 = metadata_tb[(metadata_tb.date >= 1771) & (metadata_tb.date <= 1800)]\n",
        "metadata_tb_1850 = metadata_tb[(metadata_tb.date >= 1801) & (metadata_tb.date <= 1850)]\n",
        "metadata_tb_19 = metadata_tb[(metadata_tb.date >= 1851) & (metadata_tb.date <= 1900)]\n",
        "metadata_tb_1929 = metadata_tb[(metadata_tb.date >= 1901) & (metadata_tb.date <= 1929)]"
      ],
      "metadata": {
        "id": "sC1p5MJfGb7A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process the data over time sections"
      ],
      "metadata": {
        "id": "zuIdT23KIRuC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1771-1800"
      ],
      "metadata": {
        "id": "FXjr3FDSJDZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novel_list_17 = novel_list[:len(metadata_tb_17)]"
      ],
      "metadata": {
        "id": "mmA6eAykJI1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_17 = [sentence for novel in novel_list_17 for sentence in sent_tokenize(novel)]"
      ],
      "metadata": {
        "id": "_I3s6gWsIcEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_17 = [fast_tokenize(sentence.lower()) for sentence in sentences_17]"
      ],
      "metadata": {
        "id": "wHTSPPnTIcEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence = [sentence for sentence in words_by_sentence_17 if sentence != []]"
      ],
      "metadata": {
        "id": "Ypkcn874IcEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1801-1850"
      ],
      "metadata": {
        "id": "EMJeBuLwJsec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novel_list_1850 = novel_list[len(metadata_tb_17):len(metadata_tb_17)+len(metadata_tb_1850)]"
      ],
      "metadata": {
        "id": "9pnlqdPDJsee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_1850 = [sentence for novel in novel_list_1850 for sentence in sent_tokenize(novel)]"
      ],
      "metadata": {
        "id": "6kPpGhwzJsef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_1850 = [fast_tokenize(sentence.lower()) for sentence in sentences_1850]"
      ],
      "metadata": {
        "id": "iUT8uxehJseg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_1850 = [sentence for sentence in words_by_sentence_1850 if sentence != []]"
      ],
      "metadata": {
        "id": "JzQGrClTJseh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1850-1900"
      ],
      "metadata": {
        "id": "_mRVWy9uKKkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novel_list_19 = novel_list[len(metadata_tb_1850):len(metadata_tb_1850)+len(metadata_tb_19)]"
      ],
      "metadata": {
        "id": "_8iuUHYHKKk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_19 = [sentence for novel in novel_list_19 for sentence in sent_tokenize(novel)]"
      ],
      "metadata": {
        "id": "-N_0v3RTKKk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_19 = [fast_tokenize(sentence.lower()) for sentence in sentences_19]"
      ],
      "metadata": {
        "id": "ai55Bz6LKKk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_19 = [sentence for sentence in words_by_sentence_19 if sentence != []]"
      ],
      "metadata": {
        "id": "KX9oacuiKKk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1901-1929"
      ],
      "metadata": {
        "id": "PCp355djKdfB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "novel_list_1929 = novel_list[len(metadata_tb_19):len(metadata_tb_19)+len(metadata_tb_1929)]"
      ],
      "metadata": {
        "id": "rvM6PJ5aKdfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_1929 = [sentence for novel in novel_list_1929 for sentence in sent_tokenize(novel)]"
      ],
      "metadata": {
        "id": "12yN0ffvKdfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_1929 = [fast_tokenize(sentence.lower()) for sentence in sentences_1929]"
      ],
      "metadata": {
        "id": "vwTHNpPcKdfE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_by_sentence_1929 = [sentence for sentence in words_by_sentence_1929 if sentence != []]"
      ],
      "metadata": {
        "id": "j78AYuPaKdfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a model for each time section"
      ],
      "metadata": {
        "id": "yHm-8rAJIIuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model17 = gensim.models.Word2Vec(words_by_sentence_17, size=100, window=5, \\\n",
        "                               min_count=5, sg=0, alpha=0.025, iter=15, batch_words=10000)"
      ],
      "metadata": {
        "id": "vo_J5UO-GdCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1850 = gensim.models.Word2Vec(words_by_sentence_1850, size=100, window=5, \\\n",
        "                               min_count=5, sg=0, alpha=0.025, iter=15, batch_words=10000)"
      ],
      "metadata": {
        "id": "cmbsdZjcK4xT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model19 = gensim.models.Word2Vec(words_by_sentence_19, size=100, window=5, \\\n",
        "                               min_count=5, sg=0, alpha=0.025, iter=15, batch_words=10000)"
      ],
      "metadata": {
        "id": "RBpOozdbK9g-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1929 = gensim.models.Word2Vec(words_by_sentence_1929, size=100, window=5, \\\n",
        "                               min_count=2, sg=0, alpha=0.025, iter=15, batch_words=10000)"
      ],
      "metadata": {
        "id": "Q9phAuk2Lo_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQ6QL_IyL-kw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings over time"
      ],
      "metadata": {
        "id": "BaXDSrI8N15X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"usine, corpus général (femme/homme): \", model.similarity('femme','usine')/model.similarity('homme','usine'))\n",
        "# print(\"usine au 18ème (femme/homme): \", model17.similarity('femme','usine')/model17.similarity('homme','usine'))\n",
        "print(\"usine au début du 19ème (femme/homme): \", model1850.similarity('femme','usine')/model1850.similarity('homme','usine'))\n",
        "print(\"usine à la fin du 19ème (femme/homme): \", model19.similarity('femme','usine')/model19.similarity('homme','usine'))\n",
        "print(\"usine au début du 20ème (femme/homme): \", model1929.similarity('femme','usine')/model1929.similarity('homme','usine'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjXCWNs-N3Q7",
        "outputId": "dbe62c78-532d-41cc-fa22-3bdac8518768"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usine, corpus général (femme/homme):  6.83841\n",
            "usine au début du 19ème (femme/homme):  -0.184451\n",
            "usine à la fin du 19ème (femme/homme):  -46.4917\n",
            "usine au début du 20ème (femme/homme):  1.94608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"diplomate, corpus général (femme/homme): \", model.similarity('femme','diplomate')/model.similarity('homme','diplomate'))\n",
        "# print(\"diplomate au 18ème (femme/homme): \", model17.similarity('femme','diplomate')/model17.similarity('homme','diplomate'))\n",
        "print(\"diplomate au début du 19ème (femme/homme): \", model1850.similarity('femme','diplomate')/model1850.similarity('homme','diplomate'))\n",
        "print(\"diplomate à la fin du 19ème (femme/homme): \", model19.similarity('femme','diplomate')/model19.similarity('homme','diplomate'))\n",
        "print(\"diplomate au début du 20ème (femme/homme): \", model1929.similarity('femme','diplomate')/model1929.similarity('homme','diplomate'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yLa7hz1N5jo",
        "outputId": "85d46f52-e841-4d92-c3b9-636dd5e6ccba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diplomate, corpus général (femme/homme):  0.435732\n",
            "diplomate au début du 19ème (femme/homme):  0.327662\n",
            "diplomate à la fin du 19ème (femme/homme):  0.460108\n",
            "diplomate au début du 20ème (femme/homme):  1.03136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "word_embeddings.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}